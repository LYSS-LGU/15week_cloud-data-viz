#!/usr/bin/env python3
"""
Chat Completion API ì‹¤ìŠµ ì˜ˆì œ
=========================

OpenAI Chat Completion APIë¥¼ í™œìš©í•œ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²• ì‹¤ìŠµ

ì‚¬ìš©ë²•:
1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •: OPENAI_API_KEY ë˜ëŠ” .env íŒŒì¼ì— API í‚¤ ì„¤ì •
2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install openai python-dotenv
3. ì‹¤í–‰: python chat_completion_example.py

"""

import os
import json
import time
import asyncio
from typing import List, Dict, Any
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class ChatCompletionDemo:
    """Chat Completion API ë°ëª¨ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = "gpt-4o-mini"  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸ ì‚¬ìš©
        
    def basic_chat_completion(self) -> None:
        """ê¸°ë³¸ Chat Completion ì˜ˆì œ"""
        print("=" * 50)
        print("ğŸ¤– ê¸°ë³¸ Chat Completion ì˜ˆì œ")
        print("=" * 50)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?"}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=200
            )
            
            print(f"ëª¨ë¸: {response.model}")
            print(f"ì‘ë‹µ: {response.choices[0].message.content}")
            print(f"ì‚¬ìš© í† í°: {response.usage.total_tokens}")
            print(f"ì™„ë£Œ ì´ìœ : {response.choices[0].finish_reason}")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def zero_shot_prompting(self) -> None:
        """Zero-shot í”„ë¡¬í”„íŒ… ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸ¯ Zero-shot í”„ë¡¬í”„íŒ… ì˜ˆì œ")
        print("=" * 50)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": """
ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •ì„ ê¸ì •, ë¶€ì •, ì¤‘ë¦½ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

ë¬¸ì¥: "ì´ ì œí’ˆì€ ì“¸ë§Œí•˜ì§€ë§Œ ê°€ê²©ì´ ë„ˆë¬´ ë¹„ì‹¸ìš”."

ê°ì •:"""}
        ]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.1,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ temperature
            max_tokens=10
        )
        
        print(f"Zero-shot ê²°ê³¼: {response.choices[0].message.content.strip()}")

    def few_shot_prompting(self) -> None:
        """Few-shot í”„ë¡¬í”„íŒ… ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸ“š Few-shot í”„ë¡¬í”„íŒ… ì˜ˆì œ")
        print("=" * 50)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": """
ë‹¤ìŒ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ë¥˜í•˜ì„¸ìš”.

ì˜ˆì‹œ 1:
ë¬¸ì¥: "ì´ ì œí’ˆì€ ì •ë§ ì¢‹ì•„ìš”!"
ê°ì •: ê¸ì •

ì˜ˆì‹œ 2:
ë¬¸ì¥: "ë³„ë¡œ ê¸°ëŒ€ì— ëª» ë¯¸ì¹©ë‹ˆë‹¤."
ê°ì •: ë¶€ì •

ì˜ˆì‹œ 3:
ë¬¸ì¥: "ê·¸ëƒ¥ í‰ë²”í•œ ì œí’ˆì´ë„¤ìš”."
ê°ì •: ì¤‘ë¦½

ì´ì œ ë‹¤ìŒ ë¬¸ì¥ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
ë¬¸ì¥: "ì´ ì œí’ˆì€ ì“¸ë§Œí•˜ì§€ë§Œ ê°€ê²©ì´ ë„ˆë¬´ ë¹„ì‹¸ìš”."
ê°ì •:"""}
        ]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.1,
            max_tokens=10
        )
        
        print(f"Few-shot ê²°ê³¼: {response.choices[0].message.content.strip()}")

    def role_prompting(self) -> None:
        """ì—­í•  ì§€ì • í”„ë¡¬í”„íŒ… ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸ­ ì—­í•  ì§€ì • í”„ë¡¬í”„íŒ… ì˜ˆì œ")
        print("=" * 50)
        
        # ìˆ˜í•™ ì„ ìƒë‹˜ ì—­í• 
        messages = [
            {"role": "system", "content": """
ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ ìˆ˜í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. 
í•™ìƒë“¤ì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì¹œê·¼í•˜ê³  ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""},
            {"role": "user", "content": "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."}
        ]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.7,
            max_tokens=300
        )
        
        print("ğŸ§‘â€ğŸ« ìˆ˜í•™ ì„ ìƒë‹˜ìœ¼ë¡œì„œì˜ ì„¤ëª…:")
        print(response.choices[0].message.content)

    def chain_of_thought_prompting(self) -> None:
        """Chain-of-Thought í”„ë¡¬í”„íŒ… ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸ§  Chain-of-Thought í”„ë¡¬í”„íŒ… ì˜ˆì œ")
        print("=" * 50)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë…¼ë¦¬ì  ì‚¬ê³ ë¥¼ ì¤‘ì‹œí•˜ëŠ” ë¬¸ì œ í•´ê²° ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": """
ë‹¤ìŒ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ì°¨ê·¼ì°¨ê·¼ í’€ì–´ë³´ì„¸ìš”:

ì² ìˆ˜ëŠ” ì‚¬ê³¼ 15ê°œë¥¼ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤. 
ì•„ì¹¨ì— 4ê°œë¥¼ ë¨¹ê³ , ì ì‹¬ì— ì¹œêµ¬ì—ê²Œ 6ê°œë¥¼ ë‚˜ëˆ„ì–´ ì£¼ì—ˆìŠµë‹ˆë‹¤.
ì˜¤í›„ì— ë§ˆíŠ¸ì—ì„œ 8ê°œë¥¼ ë” ìƒ€ìŠµë‹ˆë‹¤.
ì €ë…ì— 2ê°œë¥¼ ë” ë¨¹ì—ˆìŠµë‹ˆë‹¤.

ì² ìˆ˜ê°€ í˜„ì¬ ê°€ì§€ê³  ìˆëŠ” ì‚¬ê³¼ëŠ” ëª‡ ê°œì¼ê¹Œìš”?

ê° ë‹¨ê³„ë³„ë¡œ ê³„ì‚° ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”.
"""}
        ]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.3,
            max_tokens=400
        )
        
        print(response.choices[0].message.content)

    def output_format_control(self) -> None:
        """ì¶œë ¥ í¬ë§· ì œì–´ ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸ“‹ ì¶œë ¥ í¬ë§· ì œì–´ ì˜ˆì œ")
        print("=" * 50)
        
        # JSON í˜•ì‹ ì¶œë ¥ ìš”ì²­
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": """
ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

ì„œìš¸ê³¼ ë¶€ì‚° ë‘ ë„ì‹œì˜ ì˜ˆìƒ ë‚ ì”¨ ì •ë³´
- ì„œìš¸: ê¸°ì˜¨ 22ë„, ë§‘ìŒ
- ë¶€ì‚°: ê¸°ì˜¨ 25ë„, íë¦¼

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""}
        ]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.1,
            max_tokens=200
        )
        
        print("ğŸ“„ JSON í˜•ì‹ ì¶œë ¥:")
        try:
            # JSON íŒŒì‹± ê°€ëŠ¥í•œì§€ í™•ì¸
            json_str = response.choices[0].message.content.strip()
            if json_str.startswith('```json'):
                json_str = json_str.replace('```json', '').replace('```', '').strip()
            
            parsed_json = json.loads(json_str)
            print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
        except json.JSONDecodeError:
            print("ì›ë³¸ ì‘ë‹µ:")
            print(response.choices[0].message.content)

    def conversation_memory_demo(self) -> None:
        """ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬ ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸ’­ ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬ ì˜ˆì œ")
        print("=" * 50)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ëˆ„ì í•˜ëŠ” ë°©ì‹
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ì—¬í–‰ ê³„íšì„ ë„ì™€ì£¼ì„¸ìš”."}
        ]
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸
        messages.append({"role": "user", "content": "ë¶€ì‚° ì—¬í–‰ì—ì„œ ê¼­ ê°€ë´ì•¼ í•  ê³³ í•˜ë‚˜ë§Œ ì¶”ì²œí•´ì£¼ì„¸ìš”."})
        
        response1 = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.7,
            max_tokens=200
        )
        
        print("ğŸ‘¤ ì‚¬ìš©ì: ë¶€ì‚° ì—¬í–‰ì—ì„œ ê¼­ ê°€ë´ì•¼ í•  ê³³ í•˜ë‚˜ë§Œ ì¶”ì²œí•´ì£¼ì„¸ìš”.")
        print(f"ğŸ¤– AI: {response1.choices[0].message.content}")
        
        # AI ì‘ë‹µì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        messages.append({"role": "assistant", "content": response1.choices[0].message.content})
        
        # ë‘ ë²ˆì§¸ ì§ˆë¬¸ (ë§¥ë½ ìœ ì§€)
        messages.append({"role": "user", "content": "ê±°ê¸°ê¹Œì§€ ë¶€ì‚°ì—­ì—ì„œ ì–´ë–»ê²Œ ê°€ë‚˜ìš”?"})
        
        response2 = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.7,
            max_tokens=200
        )
        
        print("\nğŸ‘¤ ì‚¬ìš©ì: ê±°ê¸°ê¹Œì§€ ë¶€ì‚°ì—­ì—ì„œ ì–´ë–»ê²Œ ê°€ë‚˜ìš”?")
        print(f"ğŸ¤– AI: {response2.choices[0].message.content}")
        
        print(f"\nğŸ“Š ì´ ë©”ì‹œì§€ ìˆ˜: {len(messages)}")

    def parameter_comparison(self) -> None:
        """ë§¤ê°œë³€ìˆ˜ ë¹„êµ ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("âš™ï¸ ë§¤ê°œë³€ìˆ˜ ë¹„êµ ì˜ˆì œ")
        print("=" * 50)
        
        prompt = "ì°½ì˜ì ì¸ ë‹¨í¸ì†Œì„¤ ì•„ì´ë””ì–´ í•˜ë‚˜ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”."
        
        # Temperature ë¹„êµ
        temperatures = [0.1, 0.7, 1.5]
        
        for temp in temperatures:
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì‘ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temp,
                max_tokens=150
            )
            
            print(f"\nğŸŒ¡ï¸ Temperature {temp}:")
            print(response.choices[0].message.content)
            time.sleep(1)  # API í˜¸ì¶œ ì œí•œ ê³ ë ¤

    def streaming_response(self) -> None:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì˜ˆì œ")
        print("=" * 50)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."}
        ]
        
        print("ğŸ”„ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ:")
        print("-" * 30)
        
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=300,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    print(chunk.choices[0].delta.content, end='', flush=True)
                    
            print("\n" + "-" * 30)
            print("âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")

    def token_counting_demo(self) -> None:
        """í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ"""
        print("\n" + "=" * 50)
        print("ğŸ”¢ í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ")
        print("=" * 50)
        
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ íš¨ìœ¨ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": "Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."}
        ]
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.5,
            max_tokens=200
        )
        
        usage = response.usage
        print(f"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„:")
        print(f"   - í”„ë¡¬í”„íŠ¸ í† í°: {usage.prompt_tokens}")
        print(f"   - ì™„ë£Œ í† í°: {usage.completion_tokens}")
        print(f"   - ì´ í† í°: {usage.total_tokens}")
        
        # ëŒ€ëµì ì¸ ë¹„ìš© ê³„ì‚° (gpt-4o-mini ê¸°ì¤€)
        # ì…ë ¥: $0.00015 / 1K tokens, ì¶œë ¥: $0.0006 / 1K tokens
        input_cost = (usage.prompt_tokens / 1000) * 0.00015
        output_cost = (usage.completion_tokens / 1000) * 0.0006
        total_cost = input_cost + output_cost
        
        print(f"ğŸ’° ì˜ˆìƒ ë¹„ìš©: ${total_cost:.6f}")
        print(f"\nğŸ“ ì‘ë‹µ ë‚´ìš©:")
        print(response.choices[0].message.content)

    def run_all_demos(self) -> None:
        """ëª¨ë“  ë°ëª¨ ì‹¤í–‰"""
        print("ğŸš€ Chat Completion API ì¢…í•© ì‹¤ìŠµ ì‹œì‘!")
        print("API í‚¤ í™•ì¸:", "âœ… ì„¤ì •ë¨" if os.getenv("OPENAI_API_KEY") else "âŒ ì—†ìŒ")
        
        if not os.getenv("OPENAI_API_KEY"):
            print("\nâŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
            return
        
        demos = [
            ("ê¸°ë³¸ Chat Completion", self.basic_chat_completion),
            ("Zero-shot í”„ë¡¬í”„íŒ…", self.zero_shot_prompting),
            ("Few-shot í”„ë¡¬í”„íŒ…", self.few_shot_prompting),
            ("ì—­í•  ì§€ì • í”„ë¡¬í”„íŒ…", self.role_prompting),
            ("Chain-of-Thought", self.chain_of_thought_prompting),
            ("ì¶œë ¥ í¬ë§· ì œì–´", self.output_format_control),
            ("ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬", self.conversation_memory_demo),
            ("ë§¤ê°œë³€ìˆ˜ ë¹„êµ", self.parameter_comparison),
            ("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ", self.streaming_response),
            ("í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§", self.token_counting_demo),
        ]
        
        for i, (name, demo_func) in enumerate(demos, 1):
            try:
                print(f"\n\nğŸ“Œ [{i}/{len(demos)}] {name} ì‹¤í–‰ ì¤‘...")
                demo_func()
                time.sleep(2)  # API í˜¸ì¶œ ì œí•œ ê³ ë ¤
            except Exception as e:
                print(f"âŒ {name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        print("\n\nğŸ‰ ëª¨ë“  ë°ëª¨ ì‹¤í–‰ ì™„ë£Œ!")
        print("\nğŸ’¡ ì‹¤ìŠµ í¬ì¸íŠ¸:")
        print("   1. ê° í”„ë¡¬í”„íŠ¸ ê¸°ë²•ì˜ ì°¨ì´ì ì„ ë¹„êµí•´ë³´ì„¸ìš”")
        print("   2. Temperature ê°’ì— ë”°ë¥¸ ì‘ë‹µ ë³€í™”ë¥¼ ê´€ì°°í•˜ì„¸ìš”")
        print("   3. í† í° ì‚¬ìš©ëŸ‰ê³¼ ë¹„ìš©ì„ ê³ ë ¤í•œ ìµœì í™”ë¥¼ ìƒê°í•´ë³´ì„¸ìš”")
        print("   4. ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ì„ ì°¾ì•„ë³´ì„¸ìš”")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    demo = ChatCompletionDemo()
    
    print("=" * 60)
    print("ğŸ¤– OpenAI Chat Completion API ì‹¤ìŠµ ì˜ˆì œ")
    print("=" * 60)
    print("ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•ì„ ì‹¤ìŠµí•´ë³´ì„¸ìš”!")
    print()
    
    while True:
        print("\nğŸ“‹ ì‹¤í–‰í•  ë°ëª¨ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ì „ì²´ ë°ëª¨ ì‹¤í–‰")
        print("2. ê¸°ë³¸ Chat Completion")
        print("3. Zero-shot í”„ë¡¬í”„íŒ…")
        print("4. Few-shot í”„ë¡¬í”„íŒ…")
        print("5. ì—­í•  ì§€ì • í”„ë¡¬í”„íŒ…")
        print("6. Chain-of-Thought")
        print("7. ì¶œë ¥ í¬ë§· ì œì–´")
        print("8. ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬")
        print("9. ë§¤ê°œë³€ìˆ˜ ë¹„êµ")
        print("10. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ")
        print("11. í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§")
        print("0. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒ (0-11): ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ ì‹¤ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
            break
        elif choice == "1":
            demo.run_all_demos()
        elif choice == "2":
            demo.basic_chat_completion()
        elif choice == "3":
            demo.zero_shot_prompting()
        elif choice == "4":
            demo.few_shot_prompting()
        elif choice == "5":
            demo.role_prompting()
        elif choice == "6":
            demo.chain_of_thought_prompting()
        elif choice == "7":
            demo.output_format_control()
        elif choice == "8":
            demo.conversation_memory_demo()
        elif choice == "9":
            demo.parameter_comparison()
        elif choice == "10":
            demo.streaming_response()
        elif choice == "11":
            demo.token_counting_demo()
        else:
            print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")


if __name__ == "__main__":
    main()
